{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discutons des concepts de base de l'architecture des GANs.\n",
    "\n",
    "# Architecture de GANS\n",
    "Un GAN se compose de deux réseaux indépendants, un Générateur et un Discriminateur.\n",
    "\n",
    "Le Générateur génère des échantillons synthétiques à partir d'un bruit aléatoire (échantillonné à partir d'un espace latent) et le Discriminateur est un classificateur binaire qui distingue si l'échantillon d'entrée est réel (renvoie une valeur scalaire 1) ou faux (renvoie une valeur scalaire 0).\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/fig.1-Generator-and-Discriminator.jpg\" alt=\"Fig1: Générateur et Discriminateur en tant que blocs de construction de GAN\">\n",
    "</p>\n",
    "\n",
    "Les échantillons générés par le Générateur sont appelés des échantillons faux. Lorsqu'un point de données du jeu de données d'entraînement est donné en entrée au Discriminateur, il le considère comme un échantillon réel, tandis qu'il considère l'autre point de données comme faux lorsqu'il est généré par le Générateur.\n",
    "\n",
    "Le Discriminateur veut faire son travail de la meilleure manière possible. Lorsqu'un échantillon faux (généré par le Générateur) est donné au Discriminateur, il veut le considérer comme faux, mais le Générateur veut générer des échantillons de manière à ce que le Discriminateur fasse une erreur en le considérant comme réel. En quelque sorte, le Générateur essaie de tromper le Discriminateur.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/fig2-Generator-and-Discriminator.jpg\" alt=\"Fig2: Générateur et Discriminateur en tant que blocs de construction de GAN\">\n",
    "</p>\n",
    "\n",
    "La beauté de cette formulation réside dans la nature adversariale entre le Générateur et le Discriminateur.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function \n",
    "\n",
    "Jetons un coup d'œil rapide à la fonction objectif et à la manière dont l'optimisation est effectuée. C'est une formulation d'optimisation min-max où le Générateur veut minimiser la fonction objectif tandis que le Discriminateur veut maximiser la même fonction objectif.\n",
    "\n",
    "La premiére figure en bas en bas illustre la fonction objectif en cours d'optimisation. La fonction du Discriminateur est désignée par $D$ et la fonction du Générateur par $G$. $P_z$ est la distribution de probabilité de l'espace latent, qui est généralement une distribution gaussienne aléatoire. $P_{data}$ est la distribution de probabilité du jeu de données d'entraînement. Lorsque $x$ est échantillonné à partir de $P_{data}$, le Discriminateur veut le classer comme un échantillon réel. $G(z)$ est un échantillon généré ; lorsque $G(z)$ est donné en entrée au Discriminateur, il veut le classer comme un échantillon faux.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/fig3-Objective-function-descriminative-perspective.jpg\" alt=\"Fig3: Fonction objectif dans la formulation des GAN\">\n",
    "</p>\n",
    "\n",
    "Le Discriminateur veut amener la probabilité de $D(G(z))$ à 0. Par conséquent, il veut maximiser $(1-D(G(z)))$, tandis que le Générateur veut forcer la probabilité de $D(G(z))$ à 1 afin que le Discriminateur fasse une erreur en considérant un échantillon généré comme réel. Par conséquent, le Générateur veut minimiser $(1-D(G(z)))$.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/fig4.-Objective-function-generative-perspective.jpg\" alt=\"Fig4: Fonction objectif dans la formulation des GAN\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation Pytorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available_device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Determine if a GPU is available and set the device accordingly\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Available_device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the MNIST dataset\n",
    "data = utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST('./data', \n",
    "                               transform=torchvision.transforms.ToTensor(), \n",
    "                               download=True),\n",
    "    batch_size=128,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implémentation du Discriminateur**\n",
    "\n",
    "L'architecture du discriminateur ici comporte trois couches cachées et utilise la technique de dropout pour la régularisation. Elle utilise la fonction d'activation Leaky ReLU pour introduire la non-linéarité et la fonction Sigmoïde pour produire une probabilité. Cette configuration est essentielle pour le processus d'apprentissage adversarial dans les GANs, où le Discriminateur apprend à distinguer les images réelles des images générées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network.\n",
    "    The Discriminator classifies input images as real or fake.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear1 = nn.Linear(784, 1024)\n",
    "        self.linear2 = nn.Linear(1024, 512)\n",
    "        self.linear3 = nn.Linear(512, 256)\n",
    "        self.out = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = F.dropout(F.leaky_relu(self.linear1(x), negative_slope=0.2), p=0.3)\n",
    "        x = F.dropout(F.leaky_relu(self.linear2(x), negative_slope=0.2), p=0.3)\n",
    "        x = F.dropout(F.leaky_relu(self.linear3(x), negative_slope=0.2), p=0.3)\n",
    "        \n",
    "        return torch.sigmoid(self.out(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implémentation du Générateur**\n",
    "\n",
    "L'architecture du générateur ici comporte trois couches cachées. Le Générateur crée des images synthétiques à partir de bruit aléatoire. Il utilise la fonction d'activation Leaky ReLU pour introduire la non-linéarité et la fonction Tanh pour normaliser les valeurs des pixels des images générées dans la plage [-1, 1]. Cette configuration est essentielle pour le processus d'apprentissage adversarial dans les GANs, où le Générateur apprend à produire des images réalistes capables de tromper le Discriminateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network.\n",
    "    The Generator creates synthetic images from random noise.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear1 = nn.Linear(100, 256)\n",
    "        self.linear2 = nn.Linear(256, 512)\n",
    "        self.linear3 = nn.Linear(512, 1024)\n",
    "        self.out = nn.Linear(1024, 784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.linear1(x), negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.linear2(x), negative_slope=0.2)\n",
    "        x = F.leaky_relu(self.linear3(x), negative_slope=0.2)\n",
    "        x = torch.tanh(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss Function et optimisateur**\n",
    "\n",
    "Nous utilisons l'optimiseur Adam pour les deux modèles. L'optimiseur Adam est choisi pour sa capacité à adapter les taux d'apprentissage pour chaque paramètre individuellement, ce qui peut conduire à une convergence plus rapide et plus stable. Les taux d'apprentissage pour les deux optimiseurs sont fixés à 0.0002.\n",
    "\n",
    "Cette configuration permet d'entraîner efficacement les deux réseaux de neurones (Générateur et Discriminateur) de manière adversariale, chacun améliorant ses performances en réponse aux modifications de l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = torch.optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrainement**\n",
    "\n",
    "L'entraînement du GAN commence par la configuration du logger pour suivre et visualiser les métriques d'entraînement. \n",
    "\n",
    "Une boucle d'entraînement est exécutée pendant 50 epcohes. À chaque époque, pour chaque lot d'échantillons réels de la base de données MNIST, le Discriminateur est d'abord entraîné à distinguer entre les échantillons réels et les échantillons générés par le Générateur à partir de bruit aléatoire. Ensuite, le Générateur est entraîné à améliorer sa capacité à tromper le Discriminateur en générant des échantillons plus réalistes. \n",
    "\n",
    "Les pertes pour le Discriminateur et le Générateur sont calculées et utilisées pour mettre à jour les poids des modèles via rétropropagation. Le logger enregistre les pertes et, à intervalles réguliers, affiche l'état de l'entraînement et enregistre des images générées pour visualisation. Enfin, les paramètres des modèles sont sauvegardés à la fin de chaque époque, et le logger est fermé après la fin de l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.6952, Generator Loss: 0.7206\n",
      "D(x): 0.5031, D(G(z)): 0.4864\n",
      "Epoch: [0/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 1.4112, Generator Loss: 0.9719\n",
      "D(x): 0.2959, D(G(z)): 0.4288\n",
      "Epoch: [0/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.7556, Generator Loss: 0.7855\n",
      "D(x): 0.4524, D(G(z)): 0.4602\n",
      "Epoch: [0/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.6967, Generator Loss: 0.4956\n",
      "D(x): 0.7548, D(G(z)): 0.6123\n",
      "Epoch: [0/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.5493, Generator Loss: 0.8256\n",
      "D(x): 0.6083, D(G(z)): 0.4408\n",
      "Epoch: [1/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.7208, Generator Loss: 0.8516\n",
      "D(x): 0.4406, D(G(z)): 0.4289\n",
      "Epoch: [1/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.5490, Generator Loss: 0.8161\n",
      "D(x): 0.6960, D(G(z)): 0.4478\n",
      "Epoch: [1/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.5659, Generator Loss: 3.1000\n",
      "D(x): 0.4942, D(G(z)): 0.0596\n",
      "Epoch: [1/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.5748, Generator Loss: 4.0301\n",
      "D(x): 0.4984, D(G(z)): 0.0231\n",
      "Epoch: [1/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.5264, Generator Loss: 1.2267\n",
      "D(x): 0.6016, D(G(z)): 0.3012\n",
      "Epoch: [2/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3029, Generator Loss: 2.0224\n",
      "D(x): 0.7244, D(G(z)): 0.1479\n",
      "Epoch: [2/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2914, Generator Loss: 1.1655\n",
      "D(x): 0.9233, D(G(z)): 0.3161\n",
      "Epoch: [2/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.0809, Generator Loss: 6.0872\n",
      "D(x): 0.9569, D(G(z)): 0.0176\n",
      "Epoch: [2/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2420, Generator Loss: 3.7264\n",
      "D(x): 0.7643, D(G(z)): 0.0929\n",
      "Epoch: [2/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.5074, Generator Loss: 1.0762\n",
      "D(x): 0.6070, D(G(z)): 0.3471\n",
      "Epoch: [3/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.4650, Generator Loss: 1.1999\n",
      "D(x): 0.8061, D(G(z)): 0.3321\n",
      "Epoch: [3/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4105, Generator Loss: 1.7826\n",
      "D(x): 0.6987, D(G(z)): 0.1854\n",
      "Epoch: [3/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.5600, Generator Loss: 1.3223\n",
      "D(x): 0.6962, D(G(z)): 0.2839\n",
      "Epoch: [3/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.4200, Generator Loss: 0.8063\n",
      "D(x): 0.8651, D(G(z)): 0.4513\n",
      "Epoch: [3/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.1687, Generator Loss: 2.5175\n",
      "D(x): 0.9080, D(G(z)): 0.1286\n",
      "Epoch: [4/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.5294, Generator Loss: 3.1960\n",
      "D(x): 0.6545, D(G(z)): 0.0656\n",
      "Epoch: [4/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2939, Generator Loss: 2.1081\n",
      "D(x): 0.7589, D(G(z)): 0.1543\n",
      "Epoch: [4/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4925, Generator Loss: 2.0229\n",
      "D(x): 0.7666, D(G(z)): 0.2005\n",
      "Epoch: [4/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3608, Generator Loss: 1.8269\n",
      "D(x): 0.7940, D(G(z)): 0.2023\n",
      "Epoch: [4/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3242, Generator Loss: 2.2398\n",
      "D(x): 0.7566, D(G(z)): 0.1404\n",
      "Epoch: [5/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3361, Generator Loss: 2.0335\n",
      "D(x): 0.8090, D(G(z)): 0.1536\n",
      "Epoch: [5/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2965, Generator Loss: 2.5657\n",
      "D(x): 0.7716, D(G(z)): 0.1122\n",
      "Epoch: [5/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.8131, Generator Loss: 1.7399\n",
      "D(x): 0.6754, D(G(z)): 0.2362\n",
      "Epoch: [5/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3297, Generator Loss: 1.2926\n",
      "D(x): 0.7909, D(G(z)): 0.2885\n",
      "Epoch: [5/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2558, Generator Loss: 2.3955\n",
      "D(x): 0.8295, D(G(z)): 0.1333\n",
      "Epoch: [6/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.1246, Generator Loss: 2.1752\n",
      "D(x): 0.9236, D(G(z)): 0.1623\n",
      "Epoch: [6/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.8242, Generator Loss: 2.0564\n",
      "D(x): 0.5538, D(G(z)): 0.1907\n",
      "Epoch: [6/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3881, Generator Loss: 0.9742\n",
      "D(x): 0.8445, D(G(z)): 0.4041\n",
      "Epoch: [6/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3369, Generator Loss: 1.7914\n",
      "D(x): 0.8242, D(G(z)): 0.2078\n",
      "Epoch: [6/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4471, Generator Loss: 1.6650\n",
      "D(x): 0.7347, D(G(z)): 0.2298\n",
      "Epoch: [7/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.6465, Generator Loss: 1.5077\n",
      "D(x): 0.5646, D(G(z)): 0.2492\n",
      "Epoch: [7/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.6712, Generator Loss: 1.8137\n",
      "D(x): 0.5838, D(G(z)): 0.1884\n",
      "Epoch: [7/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4165, Generator Loss: 1.7304\n",
      "D(x): 0.7436, D(G(z)): 0.2324\n",
      "Epoch: [7/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3806, Generator Loss: 1.6835\n",
      "D(x): 0.7811, D(G(z)): 0.2143\n",
      "Epoch: [7/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.5752, Generator Loss: 1.4524\n",
      "D(x): 0.6880, D(G(z)): 0.2772\n",
      "Epoch: [8/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.4174, Generator Loss: 1.7862\n",
      "D(x): 0.7558, D(G(z)): 0.2102\n",
      "Epoch: [8/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3975, Generator Loss: 1.7901\n",
      "D(x): 0.7739, D(G(z)): 0.2388\n",
      "Epoch: [8/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3375, Generator Loss: 1.5634\n",
      "D(x): 0.8129, D(G(z)): 0.2313\n",
      "Epoch: [8/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.4524, Generator Loss: 2.3174\n",
      "D(x): 0.6696, D(G(z)): 0.1290\n",
      "Epoch: [8/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.5286, Generator Loss: 1.8868\n",
      "D(x): 0.6531, D(G(z)): 0.1784\n",
      "Epoch: [9/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.4392, Generator Loss: 1.3906\n",
      "D(x): 0.7195, D(G(z)): 0.2746\n",
      "Epoch: [9/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4019, Generator Loss: 2.3260\n",
      "D(x): 0.8011, D(G(z)): 0.2029\n",
      "Epoch: [9/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3902, Generator Loss: 1.6642\n",
      "D(x): 0.8180, D(G(z)): 0.2535\n",
      "Epoch: [9/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3234, Generator Loss: 1.4999\n",
      "D(x): 0.8056, D(G(z)): 0.2559\n",
      "Epoch: [9/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3927, Generator Loss: 1.4142\n",
      "D(x): 0.7193, D(G(z)): 0.2645\n",
      "Epoch: [10/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.6381, Generator Loss: 1.7740\n",
      "D(x): 0.6177, D(G(z)): 0.2048\n",
      "Epoch: [10/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3102, Generator Loss: 1.8282\n",
      "D(x): 0.8499, D(G(z)): 0.1915\n",
      "Epoch: [10/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3072, Generator Loss: 2.1305\n",
      "D(x): 0.8064, D(G(z)): 0.1476\n",
      "Epoch: [10/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3478, Generator Loss: 1.7667\n",
      "D(x): 0.7748, D(G(z)): 0.1910\n",
      "Epoch: [10/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3908, Generator Loss: 1.4934\n",
      "D(x): 0.7426, D(G(z)): 0.2511\n",
      "Epoch: [11/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2884, Generator Loss: 1.9833\n",
      "D(x): 0.8541, D(G(z)): 0.1722\n",
      "Epoch: [11/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.5162, Generator Loss: 1.5567\n",
      "D(x): 0.7555, D(G(z)): 0.2502\n",
      "Epoch: [11/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3916, Generator Loss: 1.5669\n",
      "D(x): 0.7685, D(G(z)): 0.2361\n",
      "Epoch: [11/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3418, Generator Loss: 1.8531\n",
      "D(x): 0.7571, D(G(z)): 0.1963\n",
      "Epoch: [11/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3706, Generator Loss: 2.3072\n",
      "D(x): 0.7833, D(G(z)): 0.1491\n",
      "Epoch: [12/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2386, Generator Loss: 2.3721\n",
      "D(x): 0.8856, D(G(z)): 0.1459\n",
      "Epoch: [12/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4412, Generator Loss: 1.5918\n",
      "D(x): 0.7143, D(G(z)): 0.2329\n",
      "Epoch: [12/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3537, Generator Loss: 1.2967\n",
      "D(x): 0.7916, D(G(z)): 0.2966\n",
      "Epoch: [12/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.6312, Generator Loss: 2.7696\n",
      "D(x): 0.5936, D(G(z)): 0.1424\n",
      "Epoch: [12/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3748, Generator Loss: 2.6252\n",
      "D(x): 0.6914, D(G(z)): 0.1432\n",
      "Epoch: [13/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.5939, Generator Loss: 2.1916\n",
      "D(x): 0.7118, D(G(z)): 0.2006\n",
      "Epoch: [13/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.5350, Generator Loss: 2.0518\n",
      "D(x): 0.6983, D(G(z)): 0.1700\n",
      "Epoch: [13/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2403, Generator Loss: 2.5764\n",
      "D(x): 0.8501, D(G(z)): 0.1199\n",
      "Epoch: [13/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.4671, Generator Loss: 2.3983\n",
      "D(x): 0.7673, D(G(z)): 0.1165\n",
      "Epoch: [13/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4550, Generator Loss: 1.6134\n",
      "D(x): 0.7609, D(G(z)): 0.2406\n",
      "Epoch: [14/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3748, Generator Loss: 1.8223\n",
      "D(x): 0.8082, D(G(z)): 0.1915\n",
      "Epoch: [14/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4879, Generator Loss: 1.6459\n",
      "D(x): 0.6661, D(G(z)): 0.2310\n",
      "Epoch: [14/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4305, Generator Loss: 1.5164\n",
      "D(x): 0.7090, D(G(z)): 0.2418\n",
      "Epoch: [14/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2842, Generator Loss: 1.9074\n",
      "D(x): 0.8737, D(G(z)): 0.1810\n",
      "Epoch: [14/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4806, Generator Loss: 1.3530\n",
      "D(x): 0.7426, D(G(z)): 0.3130\n",
      "Epoch: [15/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3022, Generator Loss: 1.9352\n",
      "D(x): 0.8193, D(G(z)): 0.1860\n",
      "Epoch: [15/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3916, Generator Loss: 2.3808\n",
      "D(x): 0.7867, D(G(z)): 0.1363\n",
      "Epoch: [15/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4956, Generator Loss: 1.5174\n",
      "D(x): 0.7071, D(G(z)): 0.2509\n",
      "Epoch: [15/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2910, Generator Loss: 2.3708\n",
      "D(x): 0.8731, D(G(z)): 0.1760\n",
      "Epoch: [15/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3445, Generator Loss: 1.9456\n",
      "D(x): 0.8003, D(G(z)): 0.1705\n",
      "Epoch: [16/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3369, Generator Loss: 1.8671\n",
      "D(x): 0.7973, D(G(z)): 0.1951\n",
      "Epoch: [16/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3832, Generator Loss: 1.8273\n",
      "D(x): 0.7572, D(G(z)): 0.2364\n",
      "Epoch: [16/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3810, Generator Loss: 2.1157\n",
      "D(x): 0.7814, D(G(z)): 0.1841\n",
      "Epoch: [16/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3915, Generator Loss: 1.5294\n",
      "D(x): 0.7727, D(G(z)): 0.2470\n",
      "Epoch: [16/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3998, Generator Loss: 1.7699\n",
      "D(x): 0.7505, D(G(z)): 0.2222\n",
      "Epoch: [17/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.4190, Generator Loss: 2.2164\n",
      "D(x): 0.7757, D(G(z)): 0.1575\n",
      "Epoch: [17/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.5306, Generator Loss: 1.6615\n",
      "D(x): 0.6432, D(G(z)): 0.2274\n",
      "Epoch: [17/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3440, Generator Loss: 2.6228\n",
      "D(x): 0.7406, D(G(z)): 0.1321\n",
      "Epoch: [17/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.4243, Generator Loss: 1.6844\n",
      "D(x): 0.6943, D(G(z)): 0.2280\n",
      "Epoch: [17/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4070, Generator Loss: 2.3156\n",
      "D(x): 0.7680, D(G(z)): 0.1332\n",
      "Epoch: [18/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.5615, Generator Loss: 1.3880\n",
      "D(x): 0.6802, D(G(z)): 0.3017\n",
      "Epoch: [18/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4357, Generator Loss: 2.3152\n",
      "D(x): 0.7334, D(G(z)): 0.1556\n",
      "Epoch: [18/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4822, Generator Loss: 2.5304\n",
      "D(x): 0.6499, D(G(z)): 0.1166\n",
      "Epoch: [18/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2647, Generator Loss: 2.0414\n",
      "D(x): 0.8245, D(G(z)): 0.1689\n",
      "Epoch: [18/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4091, Generator Loss: 1.6996\n",
      "D(x): 0.7512, D(G(z)): 0.2164\n",
      "Epoch: [19/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.4476, Generator Loss: 2.6570\n",
      "D(x): 0.7527, D(G(z)): 0.1000\n",
      "Epoch: [19/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2921, Generator Loss: 2.0337\n",
      "D(x): 0.8283, D(G(z)): 0.2133\n",
      "Epoch: [19/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4923, Generator Loss: 1.3866\n",
      "D(x): 0.7184, D(G(z)): 0.2755\n",
      "Epoch: [19/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.4243, Generator Loss: 1.9684\n",
      "D(x): 0.7186, D(G(z)): 0.1879\n",
      "Epoch: [19/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4164, Generator Loss: 1.7172\n",
      "D(x): 0.8250, D(G(z)): 0.2461\n",
      "Epoch: [20/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3704, Generator Loss: 1.7892\n",
      "D(x): 0.7633, D(G(z)): 0.1998\n",
      "Epoch: [20/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3525, Generator Loss: 1.9700\n",
      "D(x): 0.7867, D(G(z)): 0.1755\n",
      "Epoch: [20/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4658, Generator Loss: 1.7696\n",
      "D(x): 0.7294, D(G(z)): 0.2092\n",
      "Epoch: [20/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3673, Generator Loss: 1.6736\n",
      "D(x): 0.8641, D(G(z)): 0.2274\n",
      "Epoch: [20/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3357, Generator Loss: 2.2840\n",
      "D(x): 0.8265, D(G(z)): 0.1483\n",
      "Epoch: [21/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3228, Generator Loss: 2.0599\n",
      "D(x): 0.8210, D(G(z)): 0.1584\n",
      "Epoch: [21/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4300, Generator Loss: 1.5987\n",
      "D(x): 0.7918, D(G(z)): 0.2370\n",
      "Epoch: [21/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4141, Generator Loss: 1.8617\n",
      "D(x): 0.7959, D(G(z)): 0.2055\n",
      "Epoch: [21/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2819, Generator Loss: 1.6819\n",
      "D(x): 0.8244, D(G(z)): 0.2253\n",
      "Epoch: [21/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2950, Generator Loss: 2.4406\n",
      "D(x): 0.8156, D(G(z)): 0.1360\n",
      "Epoch: [22/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3097, Generator Loss: 2.0042\n",
      "D(x): 0.8130, D(G(z)): 0.1683\n",
      "Epoch: [22/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4870, Generator Loss: 1.9147\n",
      "D(x): 0.7452, D(G(z)): 0.1933\n",
      "Epoch: [22/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.5970, Generator Loss: 1.4540\n",
      "D(x): 0.6839, D(G(z)): 0.2674\n",
      "Epoch: [22/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3694, Generator Loss: 2.4548\n",
      "D(x): 0.7546, D(G(z)): 0.1943\n",
      "Epoch: [22/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4043, Generator Loss: 2.1465\n",
      "D(x): 0.7893, D(G(z)): 0.1438\n",
      "Epoch: [23/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.5922, Generator Loss: 1.6354\n",
      "D(x): 0.6590, D(G(z)): 0.2246\n",
      "Epoch: [23/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2987, Generator Loss: 1.6977\n",
      "D(x): 0.8828, D(G(z)): 0.2289\n",
      "Epoch: [23/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3501, Generator Loss: 1.9482\n",
      "D(x): 0.8129, D(G(z)): 0.1983\n",
      "Epoch: [23/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3311, Generator Loss: 1.8273\n",
      "D(x): 0.7353, D(G(z)): 0.1876\n",
      "Epoch: [23/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3089, Generator Loss: 1.6245\n",
      "D(x): 0.7959, D(G(z)): 0.2205\n",
      "Epoch: [24/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.1268, Generator Loss: 2.9376\n",
      "D(x): 0.9516, D(G(z)): 0.1117\n",
      "Epoch: [24/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4230, Generator Loss: 1.7326\n",
      "D(x): 0.7494, D(G(z)): 0.2178\n",
      "Epoch: [24/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4287, Generator Loss: 2.3275\n",
      "D(x): 0.7819, D(G(z)): 0.1704\n",
      "Epoch: [24/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3789, Generator Loss: 1.8126\n",
      "D(x): 0.7530, D(G(z)): 0.2091\n",
      "Epoch: [24/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4546, Generator Loss: 1.6950\n",
      "D(x): 0.6969, D(G(z)): 0.2164\n",
      "Epoch: [25/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2987, Generator Loss: 1.8375\n",
      "D(x): 0.8606, D(G(z)): 0.1892\n",
      "Epoch: [25/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4131, Generator Loss: 2.0819\n",
      "D(x): 0.7932, D(G(z)): 0.1649\n",
      "Epoch: [25/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4164, Generator Loss: 1.3322\n",
      "D(x): 0.7310, D(G(z)): 0.2799\n",
      "Epoch: [25/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2821, Generator Loss: 2.8409\n",
      "D(x): 0.8331, D(G(z)): 0.1100\n",
      "Epoch: [25/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4198, Generator Loss: 2.5243\n",
      "D(x): 0.7153, D(G(z)): 0.1520\n",
      "Epoch: [26/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.5103, Generator Loss: 1.7307\n",
      "D(x): 0.6865, D(G(z)): 0.2241\n",
      "Epoch: [26/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4152, Generator Loss: 1.5422\n",
      "D(x): 0.7128, D(G(z)): 0.2492\n",
      "Epoch: [26/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4441, Generator Loss: 2.3471\n",
      "D(x): 0.7344, D(G(z)): 0.1481\n",
      "Epoch: [26/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3098, Generator Loss: 1.5269\n",
      "D(x): 0.8247, D(G(z)): 0.2425\n",
      "Epoch: [26/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3944, Generator Loss: 2.4118\n",
      "D(x): 0.7533, D(G(z)): 0.1379\n",
      "Epoch: [27/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3276, Generator Loss: 2.0963\n",
      "D(x): 0.7601, D(G(z)): 0.1627\n",
      "Epoch: [27/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2592, Generator Loss: 2.0207\n",
      "D(x): 0.8432, D(G(z)): 0.1670\n",
      "Epoch: [27/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.5030, Generator Loss: 1.4988\n",
      "D(x): 0.7130, D(G(z)): 0.2764\n",
      "Epoch: [27/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2956, Generator Loss: 2.1146\n",
      "D(x): 0.8020, D(G(z)): 0.1547\n",
      "Epoch: [27/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.5579, Generator Loss: 1.8518\n",
      "D(x): 0.8297, D(G(z)): 0.2630\n",
      "Epoch: [28/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3186, Generator Loss: 1.8881\n",
      "D(x): 0.8100, D(G(z)): 0.1940\n",
      "Epoch: [28/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3304, Generator Loss: 2.2337\n",
      "D(x): 0.8142, D(G(z)): 0.1511\n",
      "Epoch: [28/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3178, Generator Loss: 2.3583\n",
      "D(x): 0.7730, D(G(z)): 0.1335\n",
      "Epoch: [28/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2759, Generator Loss: 1.8528\n",
      "D(x): 0.8311, D(G(z)): 0.2015\n",
      "Epoch: [28/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4011, Generator Loss: 2.1322\n",
      "D(x): 0.7509, D(G(z)): 0.1569\n",
      "Epoch: [29/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3799, Generator Loss: 2.2155\n",
      "D(x): 0.7941, D(G(z)): 0.1430\n",
      "Epoch: [29/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2570, Generator Loss: 1.8902\n",
      "D(x): 0.7982, D(G(z)): 0.1898\n",
      "Epoch: [29/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4744, Generator Loss: 2.2269\n",
      "D(x): 0.6889, D(G(z)): 0.1641\n",
      "Epoch: [29/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3887, Generator Loss: 1.4975\n",
      "D(x): 0.7922, D(G(z)): 0.2583\n",
      "Epoch: [29/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2909, Generator Loss: 2.3535\n",
      "D(x): 0.8161, D(G(z)): 0.1449\n",
      "Epoch: [30/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2888, Generator Loss: 2.4902\n",
      "D(x): 0.8787, D(G(z)): 0.1107\n",
      "Epoch: [30/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4298, Generator Loss: 2.1158\n",
      "D(x): 0.7198, D(G(z)): 0.1732\n",
      "Epoch: [30/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3723, Generator Loss: 2.2272\n",
      "D(x): 0.7929, D(G(z)): 0.1523\n",
      "Epoch: [30/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.5507, Generator Loss: 1.8128\n",
      "D(x): 0.7644, D(G(z)): 0.2162\n",
      "Epoch: [30/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3396, Generator Loss: 1.7972\n",
      "D(x): 0.7896, D(G(z)): 0.2016\n",
      "Epoch: [31/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3822, Generator Loss: 3.1593\n",
      "D(x): 0.7741, D(G(z)): 0.0943\n",
      "Epoch: [31/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3379, Generator Loss: 2.0129\n",
      "D(x): 0.8049, D(G(z)): 0.1873\n",
      "Epoch: [31/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.5726, Generator Loss: 1.7947\n",
      "D(x): 0.6916, D(G(z)): 0.2208\n",
      "Epoch: [31/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3662, Generator Loss: 2.3692\n",
      "D(x): 0.8251, D(G(z)): 0.1535\n",
      "Epoch: [31/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.5477, Generator Loss: 2.0035\n",
      "D(x): 0.7004, D(G(z)): 0.1899\n",
      "Epoch: [32/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2464, Generator Loss: 2.8818\n",
      "D(x): 0.8391, D(G(z)): 0.0976\n",
      "Epoch: [32/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3299, Generator Loss: 2.6784\n",
      "D(x): 0.7741, D(G(z)): 0.1125\n",
      "Epoch: [32/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4063, Generator Loss: 1.8430\n",
      "D(x): 0.8003, D(G(z)): 0.1990\n",
      "Epoch: [32/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2938, Generator Loss: 1.8359\n",
      "D(x): 0.7871, D(G(z)): 0.1959\n",
      "Epoch: [32/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2779, Generator Loss: 2.6062\n",
      "D(x): 0.8632, D(G(z)): 0.1648\n",
      "Epoch: [33/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2838, Generator Loss: 1.8509\n",
      "D(x): 0.8275, D(G(z)): 0.1774\n",
      "Epoch: [33/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2736, Generator Loss: 1.9139\n",
      "D(x): 0.8330, D(G(z)): 0.1686\n",
      "Epoch: [33/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3773, Generator Loss: 1.8061\n",
      "D(x): 0.7898, D(G(z)): 0.2056\n",
      "Epoch: [33/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3861, Generator Loss: 2.2942\n",
      "D(x): 0.7788, D(G(z)): 0.1477\n",
      "Epoch: [33/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3474, Generator Loss: 2.0776\n",
      "D(x): 0.7885, D(G(z)): 0.1624\n",
      "Epoch: [34/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3204, Generator Loss: 2.0399\n",
      "D(x): 0.8063, D(G(z)): 0.1615\n",
      "Epoch: [34/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4180, Generator Loss: 2.5698\n",
      "D(x): 0.7372, D(G(z)): 0.1497\n",
      "Epoch: [34/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2336, Generator Loss: 2.0701\n",
      "D(x): 0.8547, D(G(z)): 0.1717\n",
      "Epoch: [34/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2788, Generator Loss: 2.4245\n",
      "D(x): 0.8369, D(G(z)): 0.1120\n",
      "Epoch: [34/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4061, Generator Loss: 1.7989\n",
      "D(x): 0.8113, D(G(z)): 0.2473\n",
      "Epoch: [35/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3071, Generator Loss: 1.9213\n",
      "D(x): 0.8428, D(G(z)): 0.1966\n",
      "Epoch: [35/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3715, Generator Loss: 3.2843\n",
      "D(x): 0.7816, D(G(z)): 0.0855\n",
      "Epoch: [35/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2437, Generator Loss: 1.9370\n",
      "D(x): 0.8780, D(G(z)): 0.1756\n",
      "Epoch: [35/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3349, Generator Loss: 2.2779\n",
      "D(x): 0.8494, D(G(z)): 0.1481\n",
      "Epoch: [35/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4847, Generator Loss: 2.3489\n",
      "D(x): 0.7369, D(G(z)): 0.1545\n",
      "Epoch: [36/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2875, Generator Loss: 2.3271\n",
      "D(x): 0.8334, D(G(z)): 0.1753\n",
      "Epoch: [36/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3498, Generator Loss: 1.7518\n",
      "D(x): 0.8163, D(G(z)): 0.2097\n",
      "Epoch: [36/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4622, Generator Loss: 1.8441\n",
      "D(x): 0.7682, D(G(z)): 0.2129\n",
      "Epoch: [36/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2505, Generator Loss: 2.0624\n",
      "D(x): 0.8531, D(G(z)): 0.1583\n",
      "Epoch: [36/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3805, Generator Loss: 2.1895\n",
      "D(x): 0.7685, D(G(z)): 0.1417\n",
      "Epoch: [37/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3131, Generator Loss: 2.3264\n",
      "D(x): 0.8343, D(G(z)): 0.1492\n",
      "Epoch: [37/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3250, Generator Loss: 2.3015\n",
      "D(x): 0.7663, D(G(z)): 0.1371\n",
      "Epoch: [37/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3451, Generator Loss: 2.1150\n",
      "D(x): 0.7798, D(G(z)): 0.1643\n",
      "Epoch: [37/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.5656, Generator Loss: 1.7644\n",
      "D(x): 0.7359, D(G(z)): 0.2495\n",
      "Epoch: [37/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2525, Generator Loss: 2.6725\n",
      "D(x): 0.8504, D(G(z)): 0.1215\n",
      "Epoch: [38/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3674, Generator Loss: 1.8544\n",
      "D(x): 0.7610, D(G(z)): 0.1989\n",
      "Epoch: [38/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3096, Generator Loss: 2.9915\n",
      "D(x): 0.8129, D(G(z)): 0.0797\n",
      "Epoch: [38/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.4110, Generator Loss: 2.1542\n",
      "D(x): 0.7491, D(G(z)): 0.1681\n",
      "Epoch: [38/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.4721, Generator Loss: 2.0791\n",
      "D(x): 0.7252, D(G(z)): 0.1567\n",
      "Epoch: [38/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4211, Generator Loss: 2.3549\n",
      "D(x): 0.7135, D(G(z)): 0.1576\n",
      "Epoch: [39/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2016, Generator Loss: 2.8036\n",
      "D(x): 0.8914, D(G(z)): 0.0967\n",
      "Epoch: [39/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2534, Generator Loss: 2.8287\n",
      "D(x): 0.8521, D(G(z)): 0.1363\n",
      "Epoch: [39/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2890, Generator Loss: 1.8825\n",
      "D(x): 0.8542, D(G(z)): 0.1826\n",
      "Epoch: [39/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2715, Generator Loss: 2.7547\n",
      "D(x): 0.8580, D(G(z)): 0.1046\n",
      "Epoch: [39/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2575, Generator Loss: 2.3594\n",
      "D(x): 0.8365, D(G(z)): 0.1172\n",
      "Epoch: [40/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3317, Generator Loss: 2.1131\n",
      "D(x): 0.7851, D(G(z)): 0.1471\n",
      "Epoch: [40/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2869, Generator Loss: 2.6431\n",
      "D(x): 0.8903, D(G(z)): 0.1148\n",
      "Epoch: [40/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2567, Generator Loss: 2.3892\n",
      "D(x): 0.8794, D(G(z)): 0.1218\n",
      "Epoch: [40/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2668, Generator Loss: 1.7426\n",
      "D(x): 0.8639, D(G(z)): 0.2042\n",
      "Epoch: [40/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3428, Generator Loss: 2.0588\n",
      "D(x): 0.8287, D(G(z)): 0.1802\n",
      "Epoch: [41/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3001, Generator Loss: 2.6444\n",
      "D(x): 0.8252, D(G(z)): 0.1195\n",
      "Epoch: [41/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4086, Generator Loss: 1.9124\n",
      "D(x): 0.7209, D(G(z)): 0.2005\n",
      "Epoch: [41/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2251, Generator Loss: 2.4629\n",
      "D(x): 0.8779, D(G(z)): 0.1199\n",
      "Epoch: [41/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3270, Generator Loss: 2.4290\n",
      "D(x): 0.8005, D(G(z)): 0.1315\n",
      "Epoch: [41/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3612, Generator Loss: 2.4957\n",
      "D(x): 0.7949, D(G(z)): 0.1207\n",
      "Epoch: [42/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2273, Generator Loss: 2.2798\n",
      "D(x): 0.8302, D(G(z)): 0.1417\n",
      "Epoch: [42/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2052, Generator Loss: 2.7720\n",
      "D(x): 0.8826, D(G(z)): 0.0932\n",
      "Epoch: [42/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2828, Generator Loss: 1.8543\n",
      "D(x): 0.8456, D(G(z)): 0.1827\n",
      "Epoch: [42/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.4007, Generator Loss: 2.1979\n",
      "D(x): 0.7941, D(G(z)): 0.1688\n",
      "Epoch: [42/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4036, Generator Loss: 2.2569\n",
      "D(x): 0.7624, D(G(z)): 0.1519\n",
      "Epoch: [43/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.1811, Generator Loss: 2.5633\n",
      "D(x): 0.8859, D(G(z)): 0.1045\n",
      "Epoch: [43/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4091, Generator Loss: 2.3716\n",
      "D(x): 0.7952, D(G(z)): 0.1508\n",
      "Epoch: [43/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3548, Generator Loss: 2.0824\n",
      "D(x): 0.8137, D(G(z)): 0.1583\n",
      "Epoch: [43/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2865, Generator Loss: 2.2224\n",
      "D(x): 0.8165, D(G(z)): 0.1427\n",
      "Epoch: [43/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3350, Generator Loss: 1.8459\n",
      "D(x): 0.7998, D(G(z)): 0.1803\n",
      "Epoch: [44/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2512, Generator Loss: 2.4520\n",
      "D(x): 0.8196, D(G(z)): 0.1357\n",
      "Epoch: [44/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2987, Generator Loss: 1.8661\n",
      "D(x): 0.8282, D(G(z)): 0.1918\n",
      "Epoch: [44/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2257, Generator Loss: 2.2943\n",
      "D(x): 0.8538, D(G(z)): 0.1463\n",
      "Epoch: [44/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3388, Generator Loss: 2.6167\n",
      "D(x): 0.8309, D(G(z)): 0.1419\n",
      "Epoch: [44/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3356, Generator Loss: 2.4199\n",
      "D(x): 0.7963, D(G(z)): 0.1325\n",
      "Epoch: [45/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2599, Generator Loss: 2.8861\n",
      "D(x): 0.8485, D(G(z)): 0.0935\n",
      "Epoch: [45/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2269, Generator Loss: 3.8113\n",
      "D(x): 0.8413, D(G(z)): 0.1119\n",
      "Epoch: [45/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2788, Generator Loss: 2.5495\n",
      "D(x): 0.8249, D(G(z)): 0.1172\n",
      "Epoch: [45/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2874, Generator Loss: 2.4430\n",
      "D(x): 0.7894, D(G(z)): 0.1288\n",
      "Epoch: [45/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2456, Generator Loss: 2.2112\n",
      "D(x): 0.8355, D(G(z)): 0.1420\n",
      "Epoch: [46/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.4838, Generator Loss: 2.6565\n",
      "D(x): 0.7412, D(G(z)): 0.1438\n",
      "Epoch: [46/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3702, Generator Loss: 1.9673\n",
      "D(x): 0.7920, D(G(z)): 0.1698\n",
      "Epoch: [46/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.3173, Generator Loss: 2.1194\n",
      "D(x): 0.8182, D(G(z)): 0.1472\n",
      "Epoch: [46/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.3115, Generator Loss: 2.0933\n",
      "D(x): 0.8133, D(G(z)): 0.1675\n",
      "Epoch: [46/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.2005, Generator Loss: 2.2012\n",
      "D(x): 0.8824, D(G(z)): 0.1376\n",
      "Epoch: [47/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.2166, Generator Loss: 2.3666\n",
      "D(x): 0.8482, D(G(z)): 0.1340\n",
      "Epoch: [47/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.3658, Generator Loss: 2.1671\n",
      "D(x): 0.7507, D(G(z)): 0.1559\n",
      "Epoch: [47/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2872, Generator Loss: 2.4940\n",
      "D(x): 0.8351, D(G(z)): 0.1357\n",
      "Epoch: [47/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.1556, Generator Loss: 2.5832\n",
      "D(x): 0.9183, D(G(z)): 0.1250\n",
      "Epoch: [47/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3903, Generator Loss: 2.0903\n",
      "D(x): 0.7527, D(G(z)): 0.1769\n",
      "Epoch: [48/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.4013, Generator Loss: 2.0124\n",
      "D(x): 0.7614, D(G(z)): 0.2057\n",
      "Epoch: [48/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.2986, Generator Loss: 2.3177\n",
      "D(x): 0.8377, D(G(z)): 0.1626\n",
      "Epoch: [48/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2211, Generator Loss: 2.2389\n",
      "D(x): 0.8593, D(G(z)): 0.1359\n",
      "Epoch: [48/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.2171, Generator Loss: 2.4457\n",
      "D(x): 0.8487, D(G(z)): 0.1140\n",
      "Epoch: [48/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.3045, Generator Loss: 2.1740\n",
      "D(x): 0.8049, D(G(z)): 0.1595\n",
      "Epoch: [49/50], Batch Num: [0/469]\n",
      "Discriminator Loss: 0.3412, Generator Loss: 2.3867\n",
      "D(x): 0.7787, D(G(z)): 0.1479\n",
      "Epoch: [49/50], Batch Num: [100/469]\n",
      "Discriminator Loss: 0.4168, Generator Loss: 2.2552\n",
      "D(x): 0.7571, D(G(z)): 0.1483\n",
      "Epoch: [49/50], Batch Num: [200/469]\n",
      "Discriminator Loss: 0.2695, Generator Loss: 2.0471\n",
      "D(x): 0.8532, D(G(z)): 0.1792\n",
      "Epoch: [49/50], Batch Num: [300/469]\n",
      "Discriminator Loss: 0.5203, Generator Loss: 2.0037\n",
      "D(x): 0.7143, D(G(z)): 0.1978\n",
      "Epoch: [49/50], Batch Num: [400/469]\n",
      "Discriminator Loss: 0.4488, Generator Loss: 1.9095\n",
      "D(x): 0.7243, D(G(z)): 0.1973\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "# Logger setup\n",
    "from helpers import Logger\n",
    "logger = Logger(model_name='GAN', data_name='MNIST')\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (real_samples, _) in enumerate(data):\n",
    "        # Data for training the discriminator\n",
    "        real_samples = real_samples.view(-1, 784)\n",
    "        real_samples_labels = torch.ones((real_samples.size(0), 1))\n",
    "        latent_space_samples = torch.randn((real_samples.size(0), 100))\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((real_samples.size(0), 1))\n",
    "\n",
    "        # Concatenate real and fake data\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        output_d = discriminator(all_samples)\n",
    "        loss_d = criterion(output_d, all_samples_labels)\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Data for training the generator\n",
    "        latent_space_samples = torch.randn((real_samples.size(0), 100))\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        output_d_generated = discriminator(generated_samples)\n",
    "\n",
    "        # Reverse the labels for the generator\n",
    "        generated_samples_labels = torch.ones((real_samples.size(0), 1))\n",
    "\n",
    "        # Training the generator\n",
    "        loss_g = criterion(output_d_generated, generated_samples_labels)\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # Logging\n",
    "        logger.log(d_error=loss_d, g_error=loss_g, epoch=epoch, n_batch=n, num_batches=len(data))\n",
    "        if n % 100 == 0:\n",
    "            logger.display_status(epoch, num_epochs, n, len(data), loss_d, loss_g, discriminator(real_samples), output_d_generated)\n",
    "\n",
    "        if n % 100 == 0:\n",
    "            logger.log_images(generated_samples.view(real_samples.size(0), 1, 28, 28), num_images=real_samples.size(0), epoch=epoch, n_batch=n, num_batches=len(data))\n",
    "\n",
    "    # Save the model parameters\n",
    "    logger.save_models(generator, discriminator, epoch)\n",
    "\n",
    "# Close the logger\n",
    "logger.close()\n",
    "\n",
    "print(\"Training Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
